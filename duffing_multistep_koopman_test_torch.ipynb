{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "from scipy.fftpack import diff as psdiff\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "\n",
    "class AbstractODETarget:\n",
    "    def __init__(self, dt=1e-3, t_step=0.25, dim=2):\n",
    "        self.dim = dim\n",
    "        self.dt = dt\n",
    "        self.t_step = t_step\n",
    "        self.n_step = int(t_step / dt)\n",
    "\n",
    "    def generate_init_data(self, n_traj, traj_len, seed=None):\n",
    "        data_x = []\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        x0 = np.random.uniform(size=(n_traj, self.dim), low=self.x_min, high=self.x_max)\n",
    "\n",
    "        data_x.append(x0)\n",
    "        for t in range(traj_len - 1):\n",
    "            data_x.append(self.euler(data_x[t]))\n",
    "\n",
    "        data_x = np.asarray(data_x)\n",
    "\n",
    "        data_x = np.transpose(data_x, [1, 0, 2]).reshape(n_traj * traj_len, self.dim)\n",
    "        return np.asarray(data_x)\n",
    "\n",
    "    def generate_next_data(self, data_x):\n",
    "        data_y = self.euler(data_x)\n",
    "        return data_y\n",
    "\n",
    "    def generate_data(self, n_traj, traj_len, seed=None):\n",
    "        data_x = []\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        x0 = np.random.uniform(size=(n_traj, self.dim), low=self.x_min, high=self.x_max)\n",
    "\n",
    "        data_x.append(x0)\n",
    "        for t in range(traj_len - 1):\n",
    "            data_x.append(self.euler(data_x[t]))\n",
    "\n",
    "        data_x = np.asarray(data_x)\n",
    "        data_x = np.transpose(data_x, [1, 0, 2])\n",
    "        return np.asarray(data_x)\n",
    "\n",
    "    def rhs(self):\n",
    "        \"\"\"RHS Function :return: The rhs of one specific ODE.\"\"\"\n",
    "        return NotImplementedError\n",
    "\n",
    "    def euler(self, x):\n",
    "        \"\"\"ODE Solver.\n",
    "\n",
    "        :param x: variable\n",
    "        :type x: vector (float)\n",
    "        :return: ODE Solution at t_step after iterating the Euler method n_step times\n",
    "        :rtype: vector with the same shape as the variable x (float)\n",
    "        \"\"\"\n",
    "        for _ in range(self.n_step):\n",
    "            x = x + self.dt * self.rhs(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DuffingOscillator(AbstractODETarget):\n",
    "    \"\"\"Duffing equation based on the notation in.\n",
    "\n",
    "    (https://en.wikipedia.org/wiki/Duffing_equation)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dt=1e-3, t_step=0.25, dim=2, delta=0.5, alpha=1.0, beta=-1.0):\n",
    "        super().__init__(dt, t_step, dim)\n",
    "        self.delta = delta\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.x_min = -2\n",
    "        self.x_max = 2\n",
    "\n",
    "    def rhs(self, x):\n",
    "        x1 = x[:, 0].reshape(x.shape[0], 1)\n",
    "        x2 = x[:, 1].reshape(x.shape[0], 1)\n",
    "        f1 = x2\n",
    "        f2 = -self.delta * x2 - x1 * (self.beta + self.alpha * x1**2)\n",
    "        return np.concatenate([f1, f2], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duffing = DuffingOscillator(dt=1e-3, t_step=0.25, dim=2, delta=0.5, alpha=1.0, beta=-1.0)\n",
    "duffing_data_curr = duffing.generate_init_data(n_traj=1000, traj_len=50, seed=625)\n",
    "duffing_data_next = duffing.generate_next_data(duffing_data_curr)\n",
    "duffing_data_curr = torch.tensor(duffing_data_curr).double()\n",
    "duffing_data_next = torch.tensor(duffing_data_next).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "L = 50\n",
    "state_dim = 2\n",
    "d = state_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duffing_data = duffing.generate_data(n_traj=N, traj_len=L, seed=625)\n",
    "duffing_data = torch.tensor(duffing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(torch.tensor(duffing_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duffing_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 999\n",
    "plt.plot(duffing_data[index, :, 0], duffing_data[index, :, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractDictionary:\n",
    "    def __init__(self, n_psi_train, add_constant=True):\n",
    "        self.n_psi_train = n_psi_train\n",
    "        self.add_constant = add_constant\n",
    "\n",
    "    def generate_B(self, inputs):\n",
    "        target_dim = inputs.shape[-1]  # Get the last dimension of the input tensor\n",
    "\n",
    "        if self.add_constant:\n",
    "            self.n_psi = self.n_psi_train + target_dim + 1\n",
    "            # Initialize B matrix with zeros\n",
    "            self.B = torch.zeros(\n",
    "                (self.n_psi, target_dim), dtype=inputs.dtype, device=inputs.device\n",
    "            )\n",
    "            # Setting the sub-diagonal elements to 1\n",
    "            for i in range(target_dim):\n",
    "                self.B[i + 1, i] = 1.0\n",
    "        else:\n",
    "            self.basis_func_number = self.n_psi_train + target_dim\n",
    "            # Initialize B matrix with zeros\n",
    "            self.B = torch.zeros(\n",
    "                (self.basis_func_number, target_dim), dtype=inputs.dtype, device=inputs.device\n",
    "            )\n",
    "            # Setting the diagonal elements to 1\n",
    "            for i in range(target_dim):\n",
    "                self.B[i, i] = 1.0\n",
    "\n",
    "        return self.B\n",
    "\n",
    "\n",
    "class DicNN(nn.Module):\n",
    "    \"\"\"Trainable dictionaries.\"\"\"\n",
    "\n",
    "    def __init__(self, inputs_dim=1, layer_sizes=[64, 64], n_psi_train=22, activation_func=\"tanh\"):\n",
    "        super(DicNN, self).__init__()\n",
    "        self.inputs_dim = inputs_dim\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.n_psi_train = n_psi_train\n",
    "        self.activation_func = activation_func\n",
    "\n",
    "        # Creating the input layer\n",
    "        self.input_layer = nn.Linear(self.inputs_dim, layer_sizes[0], bias=False)\n",
    "\n",
    "        # Creating hidden layers\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for in_features, out_features in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
    "            self.hidden_layers.append(nn.Linear(in_features, out_features))\n",
    "\n",
    "        # Creating the output layer\n",
    "        self.output_layer = nn.Linear(layer_sizes[-1], n_psi_train)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Check layer dimension\n",
    "        if inputs.shape[-1] != self.inputs_dim:\n",
    "            print(f\"Error: Expected input dimension {self.inputs_dim}, but got {inputs.shape[-1]}\")\n",
    "            return None  # Optionally, you could raise an exception here\n",
    "\n",
    "        # Apply the input layer\n",
    "        psi_x_train = self.input_layer(inputs)\n",
    "\n",
    "        # Apply hidden layers with residual connections\n",
    "        for layer in self.hidden_layers:\n",
    "            if self.activation_func == \"tanh\":\n",
    "                psi_x_train = psi_x_train + F.tanh(layer(psi_x_train))\n",
    "            elif self.activation_func == \"relu\":\n",
    "                psi_x_train = psi_x_train + F.relu(layer(psi_x_train))\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        # Apply the output layer\n",
    "        outputs = self.output_layer(psi_x_train)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class PsiNN(nn.Module, AbstractDictionary):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inputs_dim=1,\n",
    "        dic_trainable=DicNN,\n",
    "        layer_sizes=[64, 64],\n",
    "        n_psi_train=22,\n",
    "        activation_func=\"tanh\",\n",
    "        add_constant=True,\n",
    "    ):\n",
    "        super(PsiNN, self).__init__()\n",
    "        self.n_psi_train = n_psi_train\n",
    "        self.add_constant = add_constant\n",
    "        # Create an instance of the dic_trainable with given parameters\n",
    "        self.dicNN = (\n",
    "            dic_trainable(inputs_dim, layer_sizes, n_psi_train, activation_func)\n",
    "            if n_psi_train != 0\n",
    "            else None\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = []\n",
    "\n",
    "        # Add a constant column of ones\n",
    "        if self.add_constant:\n",
    "            constant = torch.ones_like(inputs)[..., [0]]\n",
    "            outputs.append(constant)\n",
    "\n",
    "        # Add the original inputs\n",
    "        outputs.append(inputs)\n",
    "\n",
    "        # Add the output from dicNN if applicable\n",
    "        if self.n_psi_train != 0:\n",
    "            psi_x_train = self.dicNN(inputs)\n",
    "            outputs.append(psi_x_train)\n",
    "\n",
    "        # Concatenate along the feature dimension\n",
    "        outputs = torch.cat(outputs, dim=-1) if len(outputs) > 1 else outputs[0]\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant K Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantMatrixMultiplier(nn.Module):\n",
    "    def __init__(self, n_psi, dict_cons=True):\n",
    "        super(ConstantMatrixMultiplier, self).__init__()\n",
    "        # Initialize K as a n_spi x n_psi trainable parameter\n",
    "        self.n_psi = n_psi\n",
    "        # initial_weights = torch.eye(n_psi)*1/10\n",
    "        initial_weights = torch.randn(n_psi, n_psi)\n",
    "        self.K = nn.Parameter(initial_weights)\n",
    "        self.K.requires_grad = False\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Perform matrix multiplication\n",
    "        # inputs should be of shape (batch_size, n_psi)\n",
    "        # K is (n_psi, n_psi), so the result will be of shape (batch_size, n_psi)\n",
    "        return torch.matmul(inputs, self.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koopman Prediction Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Koopman_predictor(nn.Module):\n",
    "    def __init__(self, dict, model_K):\n",
    "        super(Koopman_predictor, self).__init__()\n",
    "        self.dict = dict\n",
    "        self.model_K = model_K\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Apply dictionary\n",
    "        psi_x = self.dict(inputs)\n",
    "        # Apply Koopman operator\n",
    "        K_psi_x = self.model_K(psi_x)\n",
    "        return K_psi_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Data Loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = 2\n",
    "layer_sizes = [256, 256, 256]\n",
    "n_psi_train = 22\n",
    "activation_func = \"tanh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_psi = 1 + state_dim + n_psi_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_nn = PsiNN(\n",
    "    inputs_dim=state_dim,\n",
    "    layer_sizes=layer_sizes,\n",
    "    n_psi_train=n_psi_train,\n",
    "    activation_func=activation_func,\n",
    ")\n",
    "model_K = ConstantMatrixMultiplier(n_psi=n_psi)\n",
    "\n",
    "Koopman_model = Koopman_predictor(dict_nn, model_K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(list(Koopman_model.parameters()), lr=1e-2)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = MyDataset(duffing_data_curr, duffing_data_next)\n",
    "\n",
    "data_loader = DataLoader(dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"min\", factor=0.8, patience=20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_K(dict, data_x, data_y, reg):\n",
    "    # Compute representations\n",
    "    psi_x = dict(data_x)\n",
    "    psi_y = dict(data_y)\n",
    "\n",
    "    # Transpose psi_x\n",
    "    psi_xt = psi_x.t()  # Transposing the matrix\n",
    "\n",
    "    # Identity matrix with the same dimension as psi_x\n",
    "    idmat = torch.eye(psi_x.shape[1], dtype=torch.float64)\n",
    "\n",
    "    # Regularized inverse computation\n",
    "    xtx = torch.mm(psi_xt, psi_x)  # Matrix multiplication of psi_xt and psi_x\n",
    "    xtx_inv = torch.pinverse(reg * idmat + xtx)  # Pseudoinverse of regularized matrix\n",
    "\n",
    "    # Matrix multiplication of psi_xt and psi_y\n",
    "    xty = torch.mm(psi_xt, psi_y)\n",
    "\n",
    "    # Compute the regularized K matrix\n",
    "    K_reg = torch.mm(xtx_inv, xty)\n",
    "\n",
    "    return K_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Koopman_model.dict(duffing_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training epochs\n",
    "# Koopman_model.to('cuda:0')\n",
    "\n",
    "\n",
    "num_epochs = 60\n",
    "loss_history = []\n",
    "T = 2\n",
    "for epoch in range(num_epochs):\n",
    "    loop = tqdm(data_loader, leave=True)\n",
    "    epoch_losses = []\n",
    "    for x in loop:\n",
    "        # x shape: (n_traj, traj_length, state_dim)\n",
    "\n",
    "        # output_pred = Koopman_model(x_curr)\n",
    "\n",
    "        # output_next = Koopman_model.dict(x_next)\n",
    "\n",
    "        psi = Koopman_model.dict(x[0])\n",
    "        target = 0\n",
    "        for i in range(L - T):\n",
    "            for j in range(T):\n",
    "                target += torch.linalg.norm(\n",
    "                    psi[:, i + j, :]\n",
    "                    - psi[:, i, :] @ torch.matrix_power(Koopman_model.model_K.K, j)\n",
    "                )\n",
    "\n",
    "        zero = torch.zeros_like(target)\n",
    "        # Compute the loss\n",
    "        loss = loss_function(target, zero)\n",
    "\n",
    "        # Zero gradients, perform a backward pass, and update the weights.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Collect loss for this batch\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "        current_lr = optimizer.param_groups[0][\"lr\"]\n",
    "\n",
    "        # Update progress bar with current loss.\n",
    "        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "        loop.set_postfix(loss=loss.item(), lr=current_lr)\n",
    "\n",
    "    # Average loss for this epoch\n",
    "    average_epoch_loss = sum(epoch_losses) / len(epoch_losses)\n",
    "    loss_history.append(average_epoch_loss)\n",
    "\n",
    "    # # Update the weights of model_K with the pinverse method\n",
    "    # psi_x = dict_nn(duffing_data_curr)\n",
    "    # psi_y = dict_nn(duffing_data_next)\n",
    "    # psi_curr_pinv = torch.pinverse(psi_x)\n",
    "    # K_weights = torch.matmul(psi_curr_pinv, psi_y)\n",
    "    # model_K.K.data = K_weights\n",
    "\n",
    "    duffing_data_curr = duffing_data[:, :-1, :]\n",
    "    duffing_data_next = duffing_data[:, 1:, :]\n",
    "    duffing_data_curr = duffing_data_curr.reshape(-1, duffing_data_curr.shape[-1])\n",
    "    duffing_data_next = duffing_data_next.reshape(-1, duffing_data_next.shape[-1])\n",
    "\n",
    "    K_weights = compute_K(Koopman_model.dict, duffing_data_curr, duffing_data_next, reg=0.01)\n",
    "    Koopman_model.model_K.K.data = K_weights\n",
    "\n",
    "    # Perform a forward pass with the updated model_K to compute the loss for the epoch\n",
    "    with torch.no_grad():\n",
    "        output_curr = Koopman_model.dict(duffing_data[:, :-1, :]).detach()\n",
    "        output_next = Koopman_model.dict(duffing_data[:, 1:, :]).detach()\n",
    "        output_pred = Koopman_model.model_K(output_curr).detach()\n",
    "        loss_total = loss_function(output_next, output_pred)\n",
    "\n",
    "    # Update learning rate based on total loss at the end of epoch\n",
    "    # scheduler.step(average_epoch_loss)\n",
    "    scheduler.step(loss_total)\n",
    "\n",
    "    # Print the loss at the end of each epoch using tqdm.write to avoid breaking the progress bar layout\n",
    "    tqdm.write(f\"Epoch {epoch + 1}/{num_epochs} finished with updated loss: {loss_total.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in Koopman_model.model_K.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = torch.linalg.eig(Koopman_model.model_K.K.data)\n",
    "sorted_indices = torch.argsort(eigenvalues.real, descending=True)\n",
    "sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "sorted_eigenvectors = eigenvectors[:, sorted_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(sorted_eigenvalues.real, sorted_eigenvalues.imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted_eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pred_soln(Koopman_model, x0, Nt):\n",
    "#     Koopman_model.eval()\n",
    "#     x_pred_list = [x0]\n",
    "\n",
    "#     psi_x0 = Koopman_model.dict(x0)\n",
    "#     psi_x_pred_list = [psi_x0]\n",
    "\n",
    "#     B = Koopman_model.dict.generate_B(x0)\n",
    "\n",
    "#     for _ in range(Nt):\n",
    "#         psi_pred = Koopman_model.model_K(psi_x_pred_list[-1])\n",
    "#         x_pred = torch.matmul(psi_pred, B)\n",
    "#         x_pred_list.append(x_pred.detach())\n",
    "#         psi_x_pred_list.append(psi_pred.detach())\n",
    "\n",
    "#     return torch.stack(x_pred_list, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_soln(Koopman_model, x0, Nt):\n",
    "    Koopman_model.eval()\n",
    "    x_pred_list = [x0]\n",
    "    # psi_x0 = Koopman_model.dict(x0)\n",
    "    # psi_pred = psi_x0\n",
    "\n",
    "    B = Koopman_model.dict.generate_B(x0)\n",
    "    x_pred = x0\n",
    "\n",
    "    for _ in range(Nt):\n",
    "        psi_pred = Koopman_model(x_pred)\n",
    "        x_pred = torch.matmul(psi_pred, B)\n",
    "        x_pred_list.append(x_pred.detach())\n",
    "\n",
    "    return torch.stack(x_pred_list, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duffing_data_test = duffing.generate_init_data(n_traj=1, traj_len=50, seed=521)\n",
    "duffing_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duffing_test_pred_iter = pred_soln(\n",
    "    Koopman_model=Koopman_model,\n",
    "    x0=torch.tensor(duffing_data_test[0]).double().reshape(1, -1),\n",
    "    Nt=test_length - 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duffing_test_pred = pred_soln(dict=dict_nn,\n",
    "#                               model_K=model_K,\n",
    "#                               x0=torch.tensor(duffing_data_curr[0]).double().reshape(1,-1),\n",
    "#                               Nt=49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(duffing_data_test[:, 0], duffing_data_test[:, 1], label=\"True\")\n",
    "plt.scatter(duffing_test_pred_iter[:, :, 0], duffing_test_pred_iter[:, :, 1], label=\"Predicted\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pk4DRP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
